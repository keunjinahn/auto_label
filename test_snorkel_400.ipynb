{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import np_utils\n",
    "import scipy\n",
    "from keras.layers import Dense\n",
    "from snorkel.labeling import labeling_function\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from snorkel.classification.data import DictDataset, DictDataLoader\n",
    "np.random.seed(5)\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt('.data\\\\maked_data_400.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:,130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:129]\n",
    "y = dataset[:,130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 114.9221 - accuracy: 0.7088\n",
      "Epoch 2/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 16.7908 - accuracy: 0.8775\n",
      "Epoch 3/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 13.5666 - accuracy: 0.8813\n",
      "Epoch 4/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 6.7381 - accuracy: 0.9200\n",
      "Epoch 5/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 5.4346 - accuracy: 0.9337\n",
      "Epoch 6/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 3.9669 - accuracy: 0.9488\n",
      "Epoch 7/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 2.1410 - accuracy: 0.9625\n",
      "Epoch 8/150\n",
      "80/80 [==============================] - 0s 562us/step - loss: 3.4040 - accuracy: 0.9500\n",
      "Epoch 9/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 3.8069 - accuracy: 0.9450\n",
      "Epoch 10/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 3.4785 - accuracy: 0.9538\n",
      "Epoch 11/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 2.6948 - accuracy: 0.9613\n",
      "Epoch 12/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.8528 - accuracy: 0.9762\n",
      "Epoch 13/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 2.2722 - accuracy: 0.9700\n",
      "Epoch 14/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 3.9895 - accuracy: 0.9513\n",
      "Epoch 15/150\n",
      "80/80 [==============================] - 0s 562us/step - loss: 1.0479 - accuracy: 0.9787\n",
      "Epoch 16/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.6275 - accuracy: 0.9787\n",
      "Epoch 17/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0346 - accuracy: 0.9787\n",
      "Epoch 18/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.7226 - accuracy: 0.9812\n",
      "Epoch 19/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.7155 - accuracy: 0.9725\n",
      "Epoch 20/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.7707 - accuracy: 0.9837\n",
      "Epoch 21/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.3006 - accuracy: 0.9937\n",
      "Epoch 22/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.2724 - accuracy: 0.9887\n",
      "Epoch 23/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.5429 - accuracy: 0.9837\n",
      "Epoch 24/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.4138 - accuracy: 0.9762\n",
      "Epoch 25/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.8695 - accuracy: 0.9800\n",
      "Epoch 26/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 0.8848 - accuracy: 0.9850\n",
      "Epoch 27/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.5225 - accuracy: 0.9787\n",
      "Epoch 28/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 2.4873 - accuracy: 0.9712\n",
      "Epoch 29/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.8853 - accuracy: 0.9787\n",
      "Epoch 30/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 0.7999 - accuracy: 0.9850\n",
      "Epoch 31/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.6828 - accuracy: 0.9887\n",
      "Epoch 32/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.0566 - accuracy: 0.9975\n",
      "Epoch 33/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 5.3762e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0140e-10 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "80/80 [==============================] - 0s 638us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "80/80 [==============================] - 0s 625us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0988e-10 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0987e-10 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0986e-10 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0985e-10 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0985e-10 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0985e-10 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0983e-10 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0985e-10 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "80/80 [==============================] - 0s 625us/step - loss: 1.0984e-10 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "80/80 [==============================] - 0s 625us/step - loss: 1.0985e-10 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0984e-10 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0984e-10 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0984e-10 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0983e-10 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0983e-10 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0982e-10 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0982e-10 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0982e-10 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0981e-10 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0981e-10 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0981e-10 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0981e-10 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0980e-10 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0979e-10 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0978e-10 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0978e-10 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0977e-10 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0976e-10 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0976e-10 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "80/80 [==============================] - 0s 562us/step - loss: 1.0973e-10 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0971e-10 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0972e-10 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0969e-10 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0970e-10 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0968e-10 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0966e-10 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0963e-10 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0961e-10 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0960e-10 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0958e-10 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0957e-10 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "80/80 [==============================] - 0s 650us/step - loss: 1.0954e-10 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0951e-10 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0946e-10 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0945e-10 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "80/80 [==============================] - 0s 613us/step - loss: 1.0939e-10 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0935e-10 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "80/80 [==============================] - 0s 600us/step - loss: 1.0930e-10 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "80/80 [==============================] - 0s 637us/step - loss: 1.0926e-10 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0921e-10 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0915e-10 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0909e-10 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0903e-10 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0895e-10 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0889e-10 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0879e-10 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0868e-10 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0860e-10 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0849e-10 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "80/80 [==============================] - 0s 588us/step - loss: 1.0838e-10 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "80/80 [==============================] - 0s 612us/step - loss: 1.0827e-10 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "80/80 [==============================] - 0s 587us/step - loss: 1.0813e-10 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "80/80 [==============================] - 0s 563us/step - loss: 1.0799e-10 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "80/80 [==============================] - 0s 575us/step - loss: 1.0784e-10 - accuracy: 1.0000\n",
      "25/25 [==============================] - 0s 520us/step - loss: 1.0767e-10 - accuracy: 1.0000\n",
      "Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(129, input_dim=129, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = loadtxt('D:\\\\project\\\\snorkel\\\\data\\\\processed_data_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = dataset2[:,0:129]\n",
    "testY = dataset2[:,130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "ns_probs = [0 for _ in range(len(testY))]\n",
    "# fit a model\n",
    "lr_probs = model.predict(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "# lr_probs = lr_probs[:, 0]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testY, ns_probs)\n",
    "lr_auc = roc_auc_score(testY, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testY, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testY, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp :  389 ,tn :  400 ,fp :  11 ,fn :  0 ,precision :  0.9725 ,recall :  1.0 ,acc :  0.98625 ,f1_score :  0.9860583016476552\n"
     ]
    }
   ],
   "source": [
    "idx  = 0\n",
    "len(result)\n",
    "equal_cnt = 0\n",
    "tp_cnt = 0\n",
    "tn_cnt = 0\n",
    "fp_cnt = 0\n",
    "fn_cnt = 0\n",
    "for r in result :\n",
    "\n",
    "    a = r[0]\n",
    "    b = int(testY[idx])\n",
    "    #print(\"r : \", r[0], \"a :\", a,\"b :\",b)\n",
    "    if r[0] >= 0.99 :\n",
    "        a = 1\n",
    "    else :\n",
    "        a = 0\n",
    "        \n",
    "    if testY[idx] >= 1 :\n",
    "        b = 1\n",
    "    else :\n",
    "        b = 0\n",
    "    if a == b :\n",
    "        equal_cnt += 1\n",
    "    if a == 1 and b == 1 :\n",
    "        tp_cnt += 1\n",
    "    if a == 0 and b == 0 :\n",
    "        tn_cnt += 1        \n",
    "    if a == 0 and b == 1 :\n",
    "        fp_cnt += 1                  \n",
    "    if a == 1 and b == 0 :\n",
    "        fn_cnt += 1          \n",
    "    idx += 1\n",
    "#print(\"tp : \",tp_cnt,\",tn : \",tn_cnt,\",fp : \",fp_cnt,\",fn : \",fn_cnt)\n",
    "precision = tp_cnt / (tp_cnt + fp_cnt)\n",
    "recall = tp_cnt / (tp_cnt + fn_cnt)\n",
    "accuracy = (tp_cnt + tn_cnt) / (tp_cnt + fn_cnt + fp_cnt + tn_cnt)\n",
    "f1_score = 2 * ((precision * recall)/ (precision + recall))\n",
    "print(\"tp : \",tp_cnt,\",tn : \",tn_cnt,\",fp : \",fp_cnt,\",fn : \",fn_cnt,\",precision : \",precision,\",recall : \",recall ,\",acc : \", accuracy,\",f1_score : \", f1_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
